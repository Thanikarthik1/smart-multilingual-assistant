ğŸŒ Smart Multilingual Assistant

A Multilingual Retrieval-Augmented Chatbot powered by FAISS, SERP API, and Llama 3 (GGUF) with support for Indian languages via translation.
Provides document + web-based answers and stores conversations in MongoDB for context-aware, accurate responses.

âœ¨ Overview

This chatbot is a hybrid RAG (Retrieval-Augmented Generation) system that combines:

âš¡ FAISS vector database â†’ Fast & semantic document retrieval

ğŸŒ Web search (SERP API + web fetcher) â†’ Real-time answers when local docs donâ€™t suffice

ğŸ§  Llama 3 (GGUF) â†’ Contextual & natural reasoning backbone

ğŸŒ IndicTrans2 â†’ Multilingual support for Indian languages

ğŸ’¾ MongoDB â†’ Persistent conversation history

ğŸ”‘ Features

âœ… Hybrid Knowledge Source â†’ Local FAISS + Google search fallback
âœ… LLM-Powered Reasoning â†’ Natural & context-aware answers
âœ… Document-Aware â†’ Upload and query your own docs
âœ… Multilingual â†’ All major Indian languages supported
âœ… Persistent Conversations â†’ Saved in MongoDB
âœ… Efficient & Scalable â†’ Quantized Llama 3 for optimized inference

ğŸ› ï¸ Tech Stack

LLM â†’ Llama 3 (GGUF Quantized)

Retrieval â†’ FAISS Vector Store

Search â†’ SERP API + Web Fetcher

Database â†’ MongoDB

Language Support â†’ IndicTrans2 Pipelines

Backend â†’ FastAPI (Python)

ğŸ“‚ Project Structure
smart-multilingual-assistant/
â”‚â”€â”€ offline-chatbot-main/
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ mistral_interface.py
â”‚   â”‚   â”œâ”€â”€ mongo_db.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
â”‚   â”‚   â””â”€â”€ hf_models/
â”‚   â”‚       â””â”€â”€ indictrans2/
â”‚   â”‚           â”œâ”€â”€ indictrans2-indic-en-dist-200M
â”‚   â”‚           â””â”€â”€ indictrans2-en-indic-dist-200M
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ ...

ğŸš€ Setup Instructions
ğŸ”½ Step 1: Clone the Repository
git clone https://github.com/Thanikarthik1/smart-multilingual-assistant.git
cd smart-multilingual-assistant/offline-chatbot-main

ğŸ“¥ Step 2: Create Model Folders
mkdir -p llm/models
mkdir -p llm/hf_models/indictrans2

ğŸ“¥ Step 3: Download Required Models

Llama 3 GGUF (Quantized)

Download Meta-Llama-3-8B-Instruct.Q4_K_M.gguf

Place it in:

llm/models/


IndicTrans2 Translation Models
Download from Hugging Face:

indictrans2-indic-en-dist-200M

indictrans2-en-indic-dist-200M

Place them in:

llm/hf_models/indictrans2/

âš™ï¸ Step 4: Install Dependencies
pip install -r requirements.txt


ğŸ“Œ Key dependencies (requirements.txt):

fastapi
uvicorn
transformers
torch==2.1.2
torchvision==0.16.2+cpu
sentence-transformers
langdetect
faiss-cpu
python-multipart
numpy==1.23.5
requests
beautifulsoup4

â–¶ï¸ Step 5: Run the Backend
uvicorn server.main:app --reload


The API will run at:
ğŸ‘‰ http://127.0.0.1:8000

Test endpoints at:
ğŸ‘‰ http://127.0.0.1:8000/docs

ğŸ“Š Architecture (Optional Visual)

(Add a diagram showing flow: User â†’ Translation â†’ FAISS + SERP â†’ Llama 3 â†’ MongoDB â†’ Response)

âœ… Features Recap

ğŸ§  RAG Chatbot â†’ FAISS + Web Search

ğŸŒ Multilingual â†’ Powered by IndicTrans2

ğŸ’¾ Persistent â†’ MongoDB storage

âš¡ Optimized â†’ Quantized Llama 3

ğŸ¤ Contributing

Contributions are welcome! ğŸ‰

Fork the repo

Create a new branch (feature/my-feature)

Commit changes (git commit -m "Added feature")

Push (git push origin feature/my-feature)

Open a Pull Request ğŸš€
